### Synchronization
To understand Synchronization, let's take an example.

Suppose, we have a class named "Counter" like this -
```
public class Counter {

    private int count = 0;

    public void increment() {
        count++;
    }

    public int getCount() {
        return count;
    }
}
```
So, it has a simple "count" variable which is incremented by 1, each time we call the "increment()" method.

And it has a getter named "getCount()" that returns the value of this "count" variable.

Now, suppose there are two different Threads from the same class that take the same object of this "Counter" class as argument in their constructors.

So, let's say this is the Thread class -
```
public class MyThread extends Thread{

    private Counter counter;

    public MyThread(Counter counter) {
        this.counter = counter;
    }

    @Override
    public void run() {
        for(int i = 0; i < 1000; i++){
            counter.increment();
        }
    }
}
```
So, all this "MyThread" class does is that it takes an object of type "Counter" as argument in the constructor and then sets the value of private variable "counter" to that object's.

Then, in the "run" method, a loop will run 1000 times and call the increment method on this "counter" object.

So, what will happen if we write the following in the main method -
```
    Counter counter = new Counter();

    MyThread t1 = new MyThread(counter);
    t1.start();

    try {
        t1.join();
    } catch (InterruptedException e) {
        System.out.println(e);
    }

    System.out.println(counter.getCount());
```
We will get "1000" in the terminal. It is the expected value right?

So, let's introduce a new Thread and that also takes the same object and does the same thing.
```
    Counter counter = new Counter();

    MyThread t1 = new MyThread(counter);
    MyThread t2 = new MyThread(counter);

    t1.start();
    t2.start();

    try {
        t1.join();
        t2.join();
    } catch (InterruptedException e) {
        System.out.println(e);
    }

    System.out.println(counter.getCount());
```
Now, what will be the output? It should be 2000 right? Because the Thread "t1" will update the value to 1000 and the Thread "t2" will update it to "2000".

But, when we run the code, we do not get "2000" all the time. Sometimes we will get "2000", sometimes we get a value lower than "2000". Why's that the case?

Do note that both the Threads are operating on the same object. This means, both of them are modifying the same "counter" object.

There is no proper "Synchronization" here which means that one thread may read the "count" value while another thread is also reading and modifying it. This can lead to incorrect results.

There is also a term called "Thread Interleaving". Since thread scheduling is managed by the operating system and is unpredictable, the exact order of thread execution is non-deterministic. The two threads may interleave their actions in a way that leads to some increments being lost.

For example:
```
- Thread 1 reads the value of count (e.g., 0).
- Thread 2 reads the same value of count (still 0).
- Both threads increment the value and write it back, but they both write 1 instead of 2, leading to a lost increment.
And this is one of the issues we face without "Synchronization".
```
To ensure that the counter's internal state is updated correctly when accessed by multiple threads, we need to synchronize access to the shared "count" variable. Without synchronization, the threads might not behave in a coordinated manner, leading to inconsistent results.

### CRITICAL SECTION
A critical section is a part of a program where shared resources (such as variables, objects, or memory) are accessed and modified by multiple threads. Since multiple threads can concurrently try to read or modify these shared resources, the critical section must be managed carefully to avoid race conditions and ensure data consistency.

If we have -
```
public void increment() {
    count++;
}
```
In this example, the count++ operation is a critical section because it's modifying a shared resource (count).

If two threads access this critical section simultaneously, they might both read the same value of count, increment it, and write back the same result, causing the counter to be incorrectly incremented only once instead of twice.

Without proper handling, critical sections can lead to race conditions, which occur when the outcome of a program depends on the interleaving of thread execution.

Here is an Example of a RACE CONDITION -

Suppose we have two threads incrementing the count at the same time:
```
- Thread 1 reads count (let’s say count = 5).
- Thread 2 reads count (also count = 5).
- Thread 1 increments count to 6 and writes the value.
- Thread 2 increments its value of 5 to 6 (it doesn't know that Thread 1 already updated it) and writes it.
- Now, instead of count being 7, it remains 6. This is a typical race condition due to unsynchronized access to the critical section.
```

### THE SOLUTION - synchronized KEYWORD
There is a keyword that Java provides which we can use in this situation. This keyword is "synchronized".

The "synchronized" keyword in Java is used to ensure that only one thread can access a particular section of code at a time, thus preventing race conditions and ensuring thread safety. When a method or block of code is marked as "synchronized", it provides mutual exclusion—meaning that only one thread can execute that "synchronized" section at a time.

And so, in our case, we know that when a Thread is executing the "increment" method, the other thread must wait before it calls the same method.

And that's why, we can do -
```
public synchronized void increment() {
    count++;
}
```
And that's it!

When a method is marked as "synchronized", it locks the object instance (or class, if the method is static) before executing the method.

In the above code, when a thread calls the "increment()" method, it acquires the lock on the Counter object. While one thread has the lock, no other thread can execute any synchronized method on the same Counter object.

### Synchronized Block:
We may not always want to synchronize the entire method. We may only want to syncrhonize some part of that method.

And in that case, we have something called a "synchronized" block.
```
public void increment() {
    synchronized (this) {
        count++;
    }
}
```
This will give us a fine-grained control.

In above code, only the code inside the "synchronized(this)" block is synchronized. This can sometimes improve performance by only locking critical sections of the code, rather than the entire method.

Why did we write "this"?

We use "synchronized(this)" to specify that the current instance of the object (i.e., this) should be used as the lock or monitor for a synchronized block of code. This ensures that only one thread can execute any synchronized block on the same object instance at a time.

When you use synchronized(this), you're saying, "Only one thread can execute this block of code at a time for this specific object instance (this)." The this keyword refers to the current object, and by synchronizing on this, you're locking the object, preventing other threads from accessing any other synchronized blocks that also lock the same object.

```
 class Counter {
    private int count = 0;

    public void increment() {
        synchronized(this) {
            count++;
            System.out.println("Incremented: " + count);
        }
    }
    public  void decrement() {
        synchronized(this) {
            count--;
            System.out.println("Decremented: " + count);
        }
    }
}
```

What will happen in this situation ?
If two threads are working on same counter object, one is calling decrement and one is calling increment, whichever thread is able to acquire the lock on (this) fisrt will fisrt finish its work and then let other thread work on (this).

### MUTUAL EXCLUSION
Mutual exclusion is a fundamental concept in concurrent programming that ensures only one thread or process can access a shared resource or critical section at a time. The primary purpose of mutual exclusion is to prevent race conditions and ensure data consistency when multiple threads or processes attempt to access and modify shared resources.

With "synchronized" keyword, we enforce "Mutual Exclusion".
